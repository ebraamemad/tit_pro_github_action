{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aa4f54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8340d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df= pd.read_csv(r'dataset\\Titanic-Dataset.csv')\n",
    "#Basic preprocessing\n",
    "df = df[['Survived', 'Pclass','Sex', 'Age', 'SibSp', 'Parch', 'Embarked','Fare']]\n",
    "df=df.dropna()\n",
    "# Encode categorical variables\n",
    "df['Sex']=LabelEncoder().fit_transform(df['Sex'])\n",
    "df['Embarked']=LabelEncoder().fit_transform(df['Embarked'])\n",
    "# Split the dataset into features and target variable\n",
    "X = df.drop('Survived', axis=1).values\n",
    "y = df['Survived'].values\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2133cfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(X, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "    \n",
    "train_ds = TitanicDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49169131",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TitanicModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(7, 64)  # 7 input features\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)   # Output layer for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))  # Sigmoid activation for binary output\n",
    "        return x\n",
    "model= TitanicModel()\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4cdb816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.9020\n",
      "Epoch [2/50], Loss: 0.7869\n",
      "Epoch [3/50], Loss: 0.3872\n",
      "Epoch [4/50], Loss: 0.5701\n",
      "Epoch [5/50], Loss: 0.4331\n",
      "Epoch [6/50], Loss: 0.6260\n",
      "Epoch [7/50], Loss: 0.5636\n",
      "Epoch [8/50], Loss: 0.5083\n",
      "Epoch [9/50], Loss: 0.5401\n",
      "Epoch [10/50], Loss: 0.6103\n",
      "Epoch [11/50], Loss: 0.5165\n",
      "Epoch [12/50], Loss: 0.5954\n",
      "Epoch [13/50], Loss: 0.4376\n",
      "Epoch [14/50], Loss: 0.3187\n",
      "Epoch [15/50], Loss: 0.3696\n",
      "Epoch [16/50], Loss: 0.6463\n",
      "Epoch [17/50], Loss: 0.5969\n",
      "Epoch [18/50], Loss: 0.8233\n",
      "Epoch [19/50], Loss: 0.6124\n",
      "Epoch [20/50], Loss: 0.4607\n",
      "Epoch [21/50], Loss: 0.3308\n",
      "Epoch [22/50], Loss: 0.5175\n",
      "Epoch [23/50], Loss: 0.2549\n",
      "Epoch [24/50], Loss: 0.5101\n",
      "Epoch [25/50], Loss: 0.3905\n",
      "Epoch [26/50], Loss: 0.7831\n",
      "Epoch [27/50], Loss: 0.1672\n",
      "Epoch [28/50], Loss: 0.5866\n",
      "Epoch [29/50], Loss: 0.5869\n",
      "Epoch [30/50], Loss: 1.0875\n",
      "Epoch [31/50], Loss: 0.3221\n",
      "Epoch [32/50], Loss: 0.3308\n",
      "Epoch [33/50], Loss: 0.5515\n",
      "Epoch [34/50], Loss: 0.8740\n",
      "Epoch [35/50], Loss: 0.3234\n",
      "Epoch [36/50], Loss: 0.2663\n",
      "Epoch [37/50], Loss: 0.3548\n",
      "Epoch [38/50], Loss: 0.3748\n",
      "Epoch [39/50], Loss: 0.3209\n",
      "Epoch [40/50], Loss: 0.3768\n",
      "Epoch [41/50], Loss: 0.5517\n",
      "Epoch [42/50], Loss: 0.1650\n",
      "Epoch [43/50], Loss: 0.1687\n",
      "Epoch [44/50], Loss: 0.3995\n",
      "Epoch [45/50], Loss: 0.5969\n",
      "Epoch [46/50], Loss: 0.3041\n",
      "Epoch [47/50], Loss: 0.3401\n",
      "Epoch [48/50], Loss: 0.3159\n",
      "Epoch [49/50], Loss: 0.7563\n",
      "Epoch [50/50], Loss: 0.4661\n"
     ]
    }
   ],
   "source": [
    "#training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    for features, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features).squeeze()  # Squeeze to match the shape of labels\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cc0d5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to titanic_model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'models/ titanic_model.pth')\n",
    "print(\"Model saved to titanic_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4eb1353c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exported to titanic_model.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch.onnx\n",
    "# Export the model to ONNX format\n",
    "dummy_input = torch.randn(1, 7)  # Adjust the input size to match the number of features    \n",
    "torch.onnx.export(model, dummy_input, \"models/titanic_model.onnx\", \n",
    "                  input_names=['input'], output_names=['output'], \n",
    "                  dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}})\n",
    "print(\"Model exported to titanic_model.onnx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tit_app_use_github_action",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
